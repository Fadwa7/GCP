Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 5
Rules claiming more threads will be scaled down.
Job stats:
job               count
--------------  -------
adapt_trimming        6
all                   1
bcalm                 2
fetch_fastq           6
files_path            1
make_fastqc           2
multi_fastqc          1
reads_count           1
reindeer              1
total                21

Select jobs to execute...
Execute 1 jobs...

[Tue Mar 12 20:55:22 2024]
Job 18: fetch fastq from NCBI
Reason: Missing output files: /home/el_fadwa1997/Results/Fastq_Files/ERR12022224/ERR12022224_1.fastq.gz

[Tue Mar 12 20:55:25 2024]
Error in rule fetch_fastq:
    jobid: 18
    output: /home/el_fadwa1997/Results/Fastq_Files/ERR12022224/ERR12022224_1.fastq.gz
    log: /home/el_fadwa1997/Results/Supplementary_Data/Logs/SRATOOLKIT/ERR12022224/ERR12022224_1.sratoolkit.log (check log file(s) for error details)
    shell:
        
                        set +eu &&
                        . $(conda info --base)/etc/profile.d/conda.sh &&
                        conda activate sratoolkit
                        prefetch ERR12022224/ERR12022224_1
                        parallel-fastq-dump                         --outdir /home/el_fadwa1997/Results/Fastq_Files                         --gzip                         --sra-id ERR12022224/ERR12022224_1                         --threads 5
			
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-03-12T205522.548690.snakemake.log
WorkflowError:
At least one job did not complete successfully.
