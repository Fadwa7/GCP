Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 2
Rules claiming more threads will be scaled down.
Job stats:
job               count
--------------  -------
adapt_trimming        4
all                   1
bcalm                 4
dump_sra              4
files_path            1
reindeer              1
sra_prefetch          4
total                19

Select jobs to execute...
Execute 1 jobs...

[Mon Feb  5 15:02:29 2024]
localrule sra_prefetch:
    output: Results/Fastq_files/sra_prefetch/SRR7093942.sra
    log: Results/Supplementary_Data/Logs/prefetch/SRR7093942.prefetch.log
    jobid: 8
    benchmark: Results/Supplementary_Data/Benchmark/prefetch/SRR7093942.prefetch.txt
    reason: Missing output files: Results/Fastq_files/sra_prefetch/SRR7093942.sra
    wildcards: sra=SRR7093942
    threads: 2
    resources: tmpdir=/tmp

Terminating processes on user request, this might take some time.
[Mon Feb  5 15:02:48 2024]
Error in rule sra_prefetch:
    jobid: 8
    output: Results/Fastq_files/sra_prefetch/SRR7093942.sra
    log: Results/Supplementary_Data/Logs/prefetch/SRR7093942.prefetch.log (check log file(s) for error details)
    shell:
        
        set +eu &&
        . $(conda info --base)/etc/profile.d/conda.sh &&
        conda activate sratoolkit
        prefetch SRR7093942 -o Results/Fastq_files/sra_prefetch/SRR7093942.sra &> Results/Supplementary_Data/Logs/prefetch/SRR7093942.prefetch.log
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Complete log: .snakemake/log/2024-02-05T150228.845089.snakemake.log
WorkflowError:
At least one job did not complete successfully.
