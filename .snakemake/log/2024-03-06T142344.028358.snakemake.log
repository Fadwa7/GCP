Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job stats:
job                 count
----------------  -------
adapt_trimming          4
all                     1
compressed_bcalm        4
total                   9

Select jobs to execute...
Execute 1 jobs...

[Wed Mar  6 14:23:44 2024]
Job 3: Trimmig FASTQS
Reason: Code has changed since last execution; Params have changed since last execution

Terminating processes on user request, this might take some time.
[Wed Mar  6 14:26:25 2024]
Error in rule adapt_trimming:
    jobid: 3
    input: /home/el_fadwa1997/Results/Fastq_Files/SRR7093894.fastq.gz
    output: /home/el_fadwa1997/Results/Trimming/SRR7093894_cutadapt.fastq.gz
    log: /home/el_fadwa1997/Results/Supplementary_Data/Logs/SRR7093894_cutadapt.log (check log file(s) for error details)
    shell:
        
        set +eu &&
        . $(conda info --base)/etc/profile.d/conda.sh &&
        conda activate cutadapt &&
        cutadapt         -j 1 -q 20 -m 20 --cores 4 -o /home/el_fadwa1997/Results/Trimming/SRR7093894_cutadapt.fastq.gz         -a AGATCGGAAGAGCACACGTCTGAACTCCAGTCA /home/el_fadwa1997/Results/Fastq_Files/SRR7093894.fastq.gz  > /home/el_fadwa1997/Results/Supplementary_Data/Logs/SRR7093894_cutadapt.log 2>&1 
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Complete log: .snakemake/log/2024-03-06T142344.028358.snakemake.log
WorkflowError:
At least one job did not complete successfully.
